{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Expectation Suite\n",
    "### Introduction\n",
    "Welcome to the tutorial! This notebook will help you run through a full example of using Grater Expectations. To repeat on what is already mentioned in the README, note that you need the following to run all the components of the tutorial:\n",
    "\n",
    "-  AWS account with [programmatic access keys](https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html)\n",
    "- [Docker Engine](https://docs.docker.com/engine/): to create new images to run on AWS Lambda and push them to ECR\n",
    "- [AWS CLI](https://aws.amazon.com/cli/): to login to AWS, create an ECR repository and push docker images to ECR\n",
    "- Python 3.8: It is recommended to use conda ([Miniconda](https://docs.conda.io/en/latest/miniconda.html)) for easy environment creation and management\n",
    "- [Terraform](https://www.terraform.io/): to spin up S3 buckets for GE artifacts and the Data Docs website and a Lambda function for testing\n",
    "- IDE (e.g. VS Code, optional): for easier development (not necessarily for notebooks, but definitely for Python files)\n",
    "\n",
    "If you have these installed, then you are ready to continue with the tutorial!\n",
    "\n",
    "<hr>\n",
    "\n",
    "In order to validate your data, Great Expectations is a package that offers a battery-included set of logic to get up-and-running fast. Fully figuring out how Great Expectations works and applying it to your project, however, can be somewhat involved. This is what Grater Expectations and this tutorial help you with!\n",
    "\n",
    "Grater Expectations makes a few choices for you and offers scripts, configurations and notebooks to get you started. The choices that were made are:\n",
    "\n",
    "- Great Expectations output will be stored on S3\n",
    "- The rendered Data Docs site will be stored on S3\n",
    "- You will write your own data loading logic to read data into memory as a pandas DataFrame\n",
    "- You will write your own set of expectations to test the quality of this data\n",
    "- The validation logic will be deployed as Docker container via AWS Lambda\n",
    "\n",
    "To set you up for the above, you already entered configurations in `testing_config.yml` for the tutorial, which will be used throughout the code to generate AWS services and access them.\n",
    "\n",
    "\n",
    "### Description\n",
    "This notebook will guide you through each of the steps to get you testing your data as soon as possible. The steps are:\n",
    "\n",
    "1. TODO\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Setting up a virtual environment\n",
    "In order to run the logic contained within this notebook, make sure that it was started up from a virtual environment that contained all required Python dependencies. The easiest way to assure this is to first make a virtual environment for the project and then call `initialize_project.py` from within it.\n",
    "\n",
    "To create a new virtual environment, e.g. for python 3.8, and installing the packages that can be found in the requirements.txt file, the commands are (ran from the root directory of this repository):\n",
    "```sh\n",
    "conda create --name <virtual_environment_name> python=3.8\n",
    "conda activate <virtual_environment_name>\n",
    "pip install -r </path/to/requirements.txt>\n",
    "```\n",
    "\n",
    "Make sure that you use this virtual environment when you run the code in this notebook, but also when you are testing the Lambda function.\n",
    "\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Provisioning S3 buckets\n",
    "For testing, Grater Expectations is configured to interact with S3 buckets on AWS. To be able to run all the code in this notebook the **store_bucket**, **site_bucket** and **data_bucket** as configured in the testing_config.yml must be provisioned.\n",
    "\n",
    "To do so, auto-generated Terraform files can be found in the *terraform/buckets* directory of this project. To use these configurations to generate S3 buckets in that directory, open a (Git bash) terminal, set your AWS programmatic access credentials as environment variables and run the following commands:\n",
    "\n",
    "```bash\n",
    "# Set credentials\n",
    "export AWS_ACCESS_KEY_ID=<enter_aws_access_key_here>\n",
    "export AWS_SECRET_ACCESS_KEY=<enter_aws_secret_access_key_here>\n",
    "\n",
    "# Go to correct Terraform directory\n",
    "cd terraform/buckets\n",
    "\n",
    "# Initialize Terraform\n",
    "terraform init\n",
    "\n",
    "# Generate deployment plan, enter yes at the prompt if the plan is correct\n",
    "terraform apply\n",
    "```\n",
    "\n",
    "Terraform will then provide you with a plan, which it will deploy if you enter 'yes' at the prompt as shown below.\n",
    "\n",
    "![Terraform bucket prompt](../docs/images/tutorial_tf_bucket_prompt.png)\n",
    "\n",
    "After entering yes, Terraform will deploy the buckets and will show you the following output when finished.\n",
    "\n",
    "![Terraform bucket apply](../docs/images/tutorial_tf_bucket_apply.png)\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and configurations\n",
    "In the cell below, packages are imported and configurations are loaded from the `project_config.yml`, which was automatically created by `initialize_project.py` and contains the configuration parameters for this tutorial.\n",
    "\n",
    "Note specifically the import of load_csv_from_s3 as load_data. For this tutorial, a function was already developed to load csv files from S3 and turn these into pandas DataFrames. You can expect the code for this function in `supporting_functions.py` or by calling `help(load_data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of Python and Grater Expectations packages and logic\n",
    "import great_expectations as ge\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "import boto3\n",
    "from supporting_functions import (TestingConfiguration,\n",
    "                                  get_file_keys_from_s3,\n",
    "                                  print_ge_site_link,\n",
    "                                  generate_link_in_notebook,\n",
    "                                  invoke_lambda_function)\n",
    "from supporting_functions import load_csv_from_s3 as load_data\n",
    "import json\n",
    "import os\n",
    "\n",
    "# -- Load parameters from configuration file\n",
    "test_config = TestingConfiguration(\"project_config.yml\")\n",
    "test_config.load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization of objects\n",
    "Next, objects required to interact with AWS from Python and a Great Expectations DataContext are initialized.\n",
    "\n",
    "By loading the GE configuration file (found in the subdirectory great_expectations), the `DataContext` object stores important parameters for you to interact with GE and automatically interact with S3 buckets for storing output, pulling checkpoints and generating Data Docs sites. For more information on data contexts, check out [the documentation](https://docs.greatexpectations.io/docs/terms/data_context/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 1. Initialize GE and S3 objects\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket = boto3.resource(\"s3\").Bucket(test_config.data_bucket)\n",
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading data to S3\n",
    "\n",
    "To emulate a *normal* setting, you will now upload the tutorial data found in this repository to the S3 data bucket you provisioned using terraform. In order to do so, the PATH_TUTORIAL_DATA constant is set to the path to the data. Next, the initialized bucket client (which is set to the data bucket) is used to upload the data to your bucket.\n",
    "\n",
    "After running the code cell below, you can enter the AWS terminal and check the S3 bucket to see if the data now resides on it. The cell automatically provides a link to the bucket that you can click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Path constant\n",
    "PATH_TUTORIAL_DATA = \"data/\"\n",
    "\n",
    "# -- Upload logic\n",
    "for dataset in os.listdir(PATH_TUTORIAL_DATA):\n",
    "    # -- Set path to file\n",
    "    path_file = os.path.abspath(PATH_TUTORIAL_DATA+dataset)\n",
    "\n",
    "    # -- Upload to S3\n",
    "    bucket.meta.client.upload_file(\n",
    "        Filename=path_file, \n",
    "        Bucket=test_config.data_bucket, \n",
    "        Key=PATH_TUTORIAL_DATA+dataset\n",
    "    )\n",
    "\n",
    "# -- Provide link to S3 bucket\n",
    "generate_link_in_notebook(f\"https://{bucket.name}.s3.amazonaws.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data\n",
    "\n",
    "The next step is to load an example dataset that can be used to create expectations for. As previously mentioned, the function `load_csv_from_s3` was already developed for this tutorial and was imported as `load` data. \n",
    "\n",
    "Having uploaded the data to S3 in the previous cell, we can now download it and transform it into a pandas DataFrame with the cell below. To know which file to load, we first get a list of objects residing on S3 using `get_file_keys_from_s3` and then pick the oldest one from this list (objects are sorted).\n",
    "\n",
    "The code of the `load_csv_from_s3` function is shown below.\n",
    "<br>\n",
    "\n",
    "```python\n",
    "def load_csv_from_s3(\n",
    "    s3_bucket_client: boto3.resource(\"s3\").Bucket, prefix: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Function to loads a csv from S3 into a pandas DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3_bucket_client : boto3.resource\n",
    "        Instantiated s3 bucket client using boto3. Note that it should already\n",
    "        be pointing to the bucket from which you want to load objects\n",
    "    prefix : str\n",
    "        Prefix to csv object on S3\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded csv object as pandas DataFrame\n",
    "    \"\"\"\n",
    "    s3_object = s3_bucket_client.Object(prefix).get()\n",
    "    df = pd.read_csv(s3_object[\"Body\"])\n",
    "\n",
    "    return df\n",
    "```\n",
    "<br>\n",
    "\n",
    "Pay special attention to what inputs this function needs and how it knows what file to load, since this will be used in the Lambda function as well. As you can see in the function source code, it will need an initialized bucket client and a prefix to an object in order to load data.\n",
    "\n",
    "Apart from the dataset, Great Expectations needs some additional parameters for operations down the line. These are an identifier for the batch being run and a name for the data asset. These can be the same, as long as they can be used to identify which dataset is being evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Get object keys from S3, sort, pick oldest\n",
    "list_objects = get_file_keys_from_s3(s3_client, test_config.data_bucket, PATH_TUTORIAL_DATA)\n",
    "list_objects.sort()\n",
    "asset_name = list_objects[0]\n",
    "\n",
    "# -- Load dataset\n",
    "df_batch = load_data(bucket, asset_name)\n",
    "batch_identifier = \"tutorial_batch_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate batch request, generate suite and start validator\n",
    "Now that the data has been loaded, this batch will be passed to a RuntimeBatchRequest below in order to start building an expectation suite. An expectation suite is Great Expectations jargon for a collection of expectations (or tests) that you want to run your data against. \n",
    "\n",
    "Great Expectations requires data to be passed as a request when you want to use the context object to generate things such as expectation suites. The RuntimeBatchRequest is used here, because we are loading data (with our own logic) at runtime and want to pass that to subsequent objects.\n",
    "\n",
    "More information on runtime batch requests can be found [here](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_configure_a_runtimedataconnector/).\n",
    "\n",
    "Using the RuntimeBatchRequest, two things are done next:\n",
    "1. Generating an expectation suite: this will serve as a collection of tests you will run for future datasets\n",
    "2. Generate a validator: this object will use the batch dataset loaded previously to start running expectations and storing these in the suite\n",
    "\n",
    "As soon as the suite and validator are initiated, you can start writing expectations in the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 3. Generate batch request at runtime using loaded tile\n",
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=\"runtime_data\",\n",
    "    data_connector_name=\"runtime_data_connector\",\n",
    "    data_asset_name=asset_name,\n",
    "    runtime_parameters={\"batch_data\": df_batch},\n",
    "    batch_identifiers={\"batch_identifier\": batch_identifier,},\n",
    ")\n",
    "\n",
    "# -- 4. Generate expectation suite, start validator\n",
    "suite = context.create_expectation_suite(\n",
    "    test_config.expectations_suite_name,\n",
    "    overwrite_existing=True,  \n",
    ")\n",
    "\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=test_config.expectations_suite_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectations\n",
    "Using the validator object, expectations can be formulated below. Since Great Expectations comes with many expectations out of the box, [this page](https://greatexpectations.io/expectations) is generally a good place to start browsing through these. \n",
    "\n",
    "Predefined expectations can be used by calling them using the validator object and passing the required arguments. For example, to run an expectation on the number of rows in a dataframe, the following snippet can be used:\n",
    "\n",
    "```python\n",
    "# Get number of rows of current batch\n",
    "row_count = df_batch.shape[0]\n",
    "\n",
    "# Make expectation where the maximum deviation from the batch number of rows is 1%\n",
    "max_delta = 0.01\n",
    "validator.expect_table_row_count_to_be_between(\n",
    "    min_value=row_count * (1-max_delta), max_value=row_count * (1+max_delta))\n",
    "```\n",
    "\n",
    "Expectations can be run both on the level of a table, e.g. evaluating the number of rows or columns, and on the level of a column, e.g. evaluating the minimum and maximum within a column. The expected values for such tests are set when generating the expectations suite using the `validator` object in the cells below and will be used for future validations.\n",
    "\n",
    "Alternatively, expectations can also be set using dynamic evaluation parameters, which is just an expensive set of words for test values that you determine at runtime. This can be useful if you for example want to compare your current dataset with the data of last month and use values in your expectations based on last month's data. An example of how to configure these dynamic evaluation parameters is shown below. More information about them can be found [here](https://docs.greatexpectations.io/docs/reference/evaluation_parameters/)\n",
    "\n",
    "Apart from existing expectations, you can also develop expectations yourself. If you want to do so, more information can be found about that [here](https://docs.greatexpectations.io/docs/guides/expectations/creating_custom_expectations/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Table level expectations\n",
    "\n",
    "# -- Constant parameters\n",
    "ROW_COUNT_DELTA = .05\n",
    "\n",
    "# -- 1. Expect future datasets to contain the same columns as current batch DataFrame\n",
    "expected_columns = df_batch.columns\n",
    "validator.expect_table_columns_to_match_set(\n",
    "    column_set=expected_columns, exact_match=True\n",
    ")\n",
    "\n",
    "# -- 2. Expect row count to be in between range, based on set delta and number of rows of batch dataset\n",
    "row_count = df_batch.shape[0]\n",
    "validator.expect_table_row_count_to_be_between(\n",
    "    min_value=row_count * (1-ROW_COUNT_DELTA), \n",
    "    max_value=row_count * (1+ROW_COUNT_DELTA),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Column level expectations\n",
    "\n",
    "# -- 1. Values are never null\n",
    "for column in expected_columns:\n",
    "    validator.expect_column_values_to_not_be_null(column)\n",
    "\n",
    "# -- 2. Date columns are parseable\n",
    "date_columns = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "for column in date_columns:\n",
    "    validator.expect_column_values_to_be_dateutil_parseable(column)\n",
    "\n",
    "# -- 3. Check dtypes, assuming dtypes of the batch dataset are correct (this is\n",
    "#       something you might rather want to hard-code for real products)\n",
    "dict_dtypes = {}\n",
    "for column, dtype in zip(df_batch.dtypes.index, df_batch.dtypes):\n",
    "    dict_dtypes[column] = str(dtype)\n",
    "\n",
    "for column, dtype in dict_dtypes.items():\n",
    "    validator.expect_column_values_to_be_of_type(column, dtype)\n",
    "\n",
    "# -- 4. Expect values of specific columns to be between lower- and upper bounds\n",
    "dict_bounds = {\"VendorID\":[1,2],\n",
    "              \"payment_type\":[1,4]\n",
    "              }\n",
    "\n",
    "for column, (lower_bound, upper_bound) in dict_bounds.items():\n",
    "    # NOTE: for large datasets, this expectation is really slow. Using seperate tests\n",
    "    # for what the minimum should be and the maximum should be is a lot faster, while\n",
    "    # achieving the same test-wise\n",
    "    validator.expect_column_values_to_be_between(column, lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Expectation using dynamic evaluation parameters. Instead of passing values directly \n",
    "#    here, a dictionary is passed with the name of the dynamic parameters along with a mock\n",
    "#    value for the current validation. At runtime, this value will need to be provided \n",
    "#    when running the validations\n",
    "\n",
    "test_column = \"passenger_count\"\n",
    "max_passenger_count = df_batch[test_column].max()\n",
    "\n",
    "validator.expect_column_max_to_be_between(\n",
    "    column=test_column,\n",
    "    min_value={\n",
    "        \"$PARAMETER\": \"min_max_passenger_count\",\n",
    "        \"$PARAMETER.min_max_passenger_count\": max_passenger_count\n",
    "        },\n",
    "    max_value={\n",
    "        \"$PARAMETER\": \"max_max_passenger_count\",\n",
    "        \"$PARAMETER.max_max_passenger_count\": max_passenger_count+2\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize suite and create checkpoint\n",
    "After running all the expectations in the cells above, the cell below can be executed to save this set of expectations as a suite and couple it with a checkpoint. \n",
    "\n",
    "A checkpoint is an object which can be called by validation logic to run new data batches against, coupling an expectation_suite with parameters to a name. In addition, actions can be coupled to this checkpoint, such as automatically updating the Data Docs website or sending a message on Slack. \n",
    "\n",
    "This checkpoint can be used in other scripts (lambda_function.py) by passing a new batch of data (as RuntimeBatchRequest) along with the checkpoint name to the `run_checkpoint` method of an initialized DataContext (which is the same as the `context` object initialized in this notebook). Such a call would look like:\n",
    "\n",
    "```python\n",
    "results = context.run_checkpoint(\n",
    "    checkpoint_name=\"CHECKPOINT_NAME\",\n",
    "    validations=[{\"batch_request\": batch_request}],\n",
    "    )\n",
    "```\n",
    "\n",
    "When the code below is ran, Great Expectations automatically saves the expectation suite and checkpoint to S3 via the validator and context objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 6. Save suite\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "# -- 7.1 Create Simple checkpoint with automatic data docs updates\n",
    "checkpoint_config = {\n",
    "    \"name\": test_config.checkpoint_name,\n",
    "    \"config_version\": 3,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"expectation_suite_name\": test_config.expectations_suite_name,\n",
    "    \"run_name_template\": test_config.run_name_template,\n",
    "}\n",
    "\n",
    "# -- 7.2 Add to context object\n",
    "context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Data Docs website\n",
    "Next, the command below can be ran to build the Data Docs website on S3, which provides an interactive user interface in which you can browse through expectation suites and check validation results. More on Data Docs can be found [here](https://docs.greatexpectations.io/docs/reference/data_docs/)\n",
    "\n",
    "If you use a SimpleCheckpoint, as is the case in this tutorial, the website will automatically be updated each time validaitons are run. If not, you have to either manually or programmatically update the Data Docs website but calling `context.build_data_docs()`\n",
    "\n",
    "After initializing the Data Docs website, you should be able to see the expectation suite we just generated. In the following steps, we will start running validations, which well then also appear on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_site_output = context.build_data_docs()\n",
    "print_ge_site_link(ge_site_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Develop logic for Lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Docker Image and deploy on AWS Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "After you have run all of the steps above, instantiated a Data Docs website and can see your expectation suite there, you are ready to proceed with developing the logic for the Lambda function in `lambda_function.py`, creating a Docker Image with that, uploading that to ECR and deploying it as a Lambda function.\n",
    "\n",
    "Please refer to the README for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Jupyter server\n",
    "After running all commands above and generating an expectation suite, checkpoint and website, run the command below to stop the Jupyter server from running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"jupyter notebook stop\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f144a048924e6ba956c9d413606a70b7f1d7be8d03d8407a2b6201ce5707b74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('grater_expectations')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
